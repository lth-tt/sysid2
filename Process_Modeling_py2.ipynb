{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import identification_py2 as ident_tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import control as con\n",
    "import glob #for returning files having the specified path extension\n",
    "import statistics as stats\n",
    "import os #checking for empty file\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Passing all the data into arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_first        = sorted(glob.glob('step_log_new/*/*task*.log')) #corresponds to .log files that has data related to the first position\n",
    "control_first     = sorted(glob.glob('step_log_new/*/*control*.log'))\n",
    "task_remaining    = sorted(glob.glob('step_log_new/*/*task*.log.*')) #corresponds to remaining log.'n' files\n",
    "control_remaining = sorted(glob.glob('step_log_new/*/*control*.log.*'))\n",
    "task              = sorted(task_first + task_remaining) #set of all task_velocity logs\n",
    "control           = sorted(control_first + control_remaining) #set of all control logs\n",
    "observations      = len(task_first) #total number of experiments conducted/observations taken\n",
    "positions         = int(len(task) / observations) #number of points in the given task space\n",
    "task_full         = [] #A task_velocity list whose each element is a list of similar log files i.e from the same position\n",
    "control_full      = [] #A control_output list whose each element is a list of similar log files i.e from the same position\n",
    "\n",
    "for i in range(0, positions):\n",
    "    task_full.append([])\n",
    "    control_full.append([])\n",
    "    for j in range(0, observations):\n",
    "        task_full[i].append(task[i + (j * positions)])\n",
    "        control_full[i].append(control[i + (j * positions)])\n",
    "\n",
    "count = 0 #counter that returns the number of empty files\n",
    "for i in range(0, positions):\n",
    "    for j in range(0, observations):\n",
    "        if os.stat(task_full[i][j]).st_size == 0:\n",
    "            count = count + 1\n",
    "            \n",
    "for i in range(0, positions):\n",
    "    for j in range(0, observations-count):\n",
    "        if os.stat(task_full[i][j]).st_size == 0:\n",
    "            del(task_full[i][j])\n",
    "            del(control_full[i][j])\n",
    "            \n",
    "# Reading all the data into a dataframe array\n",
    "df_ist_soll = []\n",
    "model_estimations = []\n",
    "\n",
    "for i in range(0, positions):\n",
    "    df_ist_soll.append([])\n",
    "    model_estimations.append([])\n",
    "    for j in range(0, observations):\n",
    "        try:\n",
    "            # initialize result dictionary\n",
    "            model_estimations[i].append({})\n",
    "            df_ist_soll[i].append(ident_tools.batch_read_data(control_full[i][j], task_full[i][j]))\n",
    "        except:\n",
    "            print \"Some Error occured and was ignored\"\n",
    "            continue\n",
    "            \n",
    "print \"############################### INFO #########################################\"\n",
    "print \"df_ist_soll contains all reference and actual data per each position and each experiement\"\n",
    "print\n",
    "print \"df_ist_soll[position][experiement] -> pandas.Dataframe{'x_ist', 'x_soll'}\"\n",
    "print \"model_estimations[position][experiement] -> dict{'delay', 'scale_factor', ...}\"\n",
    "print \"############################### INFO #########################################\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Manually changing the setpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0, observations):\n",
    "#    df_ist_soll[0][i].x_soll[df_ist_soll[0][i].x_soll > 0] = 0.15\n",
    "#    df_ist_soll[3][i].x_soll[df_ist_soll[3][i].x_soll > 0] = 0.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Displaying all the observations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The first try except code avoids the errors arising due to the already existing Overview directory. \n",
    "# The second try except code avoids the errors resulting from the plotting of the empty data file \n",
    "try:\n",
    "    os.makedirs('View_Data/')\n",
    "except OSError, e:\n",
    "    if e.errno != os.errno.EEXIST:\n",
    "        raise   \n",
    "    pass\n",
    "\n",
    "for i in range(0, positions):\n",
    "    fig = plt.figure(figsize = (10,30))\n",
    "    fig.suptitle('Position %s'%(i + 1), fontsize = 20, fontweight = 'bold')\n",
    "    for j in range(0, observations): \n",
    "        try:\n",
    "            ax = fig.add_subplot(observations, 1, j + 1)\n",
    "            ax.set_title('Observation %s'%(j + 1))\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.plot(df_ist_soll[i][j]) \n",
    "        except:\n",
    "            pass\n",
    "    plt.savefig('View_Data/Position %s.png'%(i + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Smoothing using Savgol filter and normalization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df_pos in enumerate(df_ist_soll):\n",
    "    for j, df_exp in enumerate(df_pos):\n",
    "        \n",
    "        # The following expects the unit step to be single and alone per experiement!\n",
    "        if len(df_exp.x_soll.value_counts()) > 2:\n",
    "            print \"WARNING! - Data in Position {0}, Experiement {1} (df_ist_soll[{0}][{1}])\".format(i, j)\n",
    "            print \"has more than {} different values\". format(len(df_exp.x_soll.value_counts()))\n",
    "            print \"!!!! This could lead to wrong calculations!!!!\"\n",
    "            print \"!!!! Target values should be either Zero (beginning) or step height (until end)!!!!\"\n",
    "            print df_exp.x_soll.value_counts()\n",
    "\n",
    "        factor = 1.0/max(df_exp.x_soll)\n",
    "        model_estimations[i][j]['step_height'] = max(df_exp.x_soll)\n",
    "        model_estimations[i][j]['scale_factor'] = factor\n",
    "        df_ist_soll[i][j] = pd.concat(\n",
    "            [df_ist_soll[i][j],\n",
    "            pd.DataFrame(\n",
    "                factor*np.array(df_exp.x_ist),\n",
    "                columns=['normalized'],\n",
    "                index=df_exp.index)],\n",
    "            axis=1)\n",
    "        \n",
    "        for order in range(1, 4):\n",
    "            df_ist_soll[i][j] = pd.concat(\n",
    "                [df_ist_soll[i][j],\n",
    "                pd.DataFrame(\n",
    "                    ident_tools.smooth(factor*np.array(df_exp.x_ist), order),\n",
    "                    columns=['smooth_{}'.format(order)],\n",
    "                    index=df_exp.index)],\n",
    "                axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ist_soll[0][0].plot()\n",
    "print df_ist_soll[0][0].head()\n",
    "\n",
    "print model_estimations[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PT1 + PT2 Estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, df_pos in enumerate(df_ist_soll):\n",
    "    for j, df_exp in enumerate(df_pos):\n",
    "        \n",
    "        for order in range(1,4):\n",
    "            # PT1 Estimations\n",
    "            tf, _, _, delay, time_constant, steady_state, tf_without_delay =\\\n",
    "                ident_tools.pt1(np.array(df_exp['smooth_{}'.format(order)]), np.array(df_exp.index))\n",
    "            pt1_dict = {\n",
    "                'tf_delay': tf,\n",
    "                'tf': tf_without_delay,\n",
    "                'delay': delay,\n",
    "                'time_constant': time_constant,\n",
    "                'steady_state': steady_state\n",
    "            }\n",
    "            model_estimations[i][j]['pt1_smooth_{}'.format(order)] = pt1_dict\n",
    "        \n",
    "        for order in range(1,4):\n",
    "            try:\n",
    "                tf, _, _, delay, time_constant, steady_state, zeta, tf_without_delay =\\\n",
    "                    ident_tools.pt2(np.array(df_exp['smooth_{}'.format(order)]), np.array(df_exp.index))\n",
    "\n",
    "                pt2_dict = {\n",
    "                    'tf_delay': tf,\n",
    "                    'tf': tf_without_delay,\n",
    "                    'delay': delay,\n",
    "                    'time_constant': time_constant,\n",
    "                    'steady_state': steady_state,\n",
    "                    'zeta': zeta,\n",
    "                }\n",
    "                model_estimations[i][j]['pt2_smooth_{}'.format(order)] = pt2_dict\n",
    "            except:\n",
    "                print \"PT2 Estimation failed (smoothed_{2})! Position {0}, Experiement {1}; df_ist_soll[{0}][{1}]\".format(i, j, order)\n",
    "                #model_estimations[i][j]['pt2_smooth_{}'.format(order)] = None\n",
    "\n",
    "        try:\n",
    "            tf, _, _, delay, time_constant, steady_state, zeta, tf_without_delay =\\\n",
    "                ident_tools.pt2(np.array(df_exp['normalized']), np.array(df_exp.index))\n",
    "\n",
    "            pt2_dict = {\n",
    "                'tf_delay': tf,\n",
    "                'tf': tf_without_delay,\n",
    "                'delay': delay,\n",
    "                'time_constant': time_constant,\n",
    "                'steady_state': steady_state,\n",
    "                'zeta': zeta,\n",
    "            }\n",
    "            model_estimations[i][j]['pt2'] = pt2_dict\n",
    "        except:\n",
    "            print \"PT2 Estimation failed (normalized)! Position {0}, Experiement {1}; df_ist_soll[{0}][{1}]\".format(i, j)\n",
    "            #model_estimations[i][j]['pt2'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print model_estimations[0][0].keys()\n",
    "print model_estimations[0][0]['pt2_smooth_2'].keys()\n",
    "\n",
    "t0, y0 = con.step_response(model_estimations[0][0]['pt2_smooth_2']['tf'])\n",
    "t1, y1 = con.step_response(model_estimations[0][0]['pt1_smooth_1']['tf_delay'])\n",
    "t2, y2 = con.step_response(model_estimations[0][0]['pt2_smooth_2']['tf_delay'])\n",
    "\n",
    "plot(t0+model_estimations[0][0]['pt2_smooth_2']['delay'], y0, label='shifted pt2')\n",
    "#plot(t1, y1, label='pt1d')\n",
    "plot(t2, y2, label='pt2d')\n",
    "plot(df_ist_soll[0][0]['normalized'], label='data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Average values over position and experiement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_all_experiements(pos, est_sys_key, paramerter_key):\n",
    "    res = []\n",
    "    for j, exp in enumerate(model_estimations[pos]):\n",
    "        if est_sys_key in model_estimations[pos][j]:\n",
    "            res.append(model_estimations[pos][j][est_sys_key][paramerter_key])\n",
    "    return res\n",
    "\n",
    "def from_every_experiement(est_sys_key, paramerter_key):\n",
    "    res = []\n",
    "    for i, pos in enumerate(model_estimations):\n",
    "        for j, exp in enumerate(pos):\n",
    "            if est_sys_key in pos[j]:\n",
    "                res.append(exp[est_sys_key][paramerter_key])\n",
    "    return res\n",
    "\n",
    "print from_all_experiements(0, 'pt1_smooth_2', 'steady_state')\n",
    "print\n",
    "print from_every_experiement('pt1_smooth_2', 'steady_state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### State Space Parameters of all the ideal models in a textfile"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(\"State_Space_Parameters_pt1.txt\", \"w\") as text_file:\n",
    "    text_file.write('###########################\\n')\n",
    "    text_file.write('  STATE SPACE PARAMETERS   \\n')\n",
    "    text_file.write('###########################\\n')\n",
    "    for i in range(0, positions):\n",
    "        text_file.write('\\nPosition %s\\n'%(i+1))\n",
    "        text_file.write('%s'%system_matrix_pt1[i])\n",
    "        text_file.write('\\n')\n",
    "        \n",
    "with open(\"State_Space_Parameters_pt2.txt\", \"w\") as text_file:\n",
    "    text_file.write('###########################\\n')\n",
    "    text_file.write('  STATE SPACE PARAMETERS   \\n')\n",
    "    text_file.write('###########################\\n')\n",
    "    for i in range(0, positions):\n",
    "        text_file.write('\\nPosition %s\\n'%(i+1))\n",
    "        text_file.write('%s'%system_matrix_pt2[i])\n",
    "        text_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model Validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "try:\n",
    "    os.makedirs('Model_Validation/')\n",
    "except OSError, e:\n",
    "    if e.errno != os.errno.EEXIST:\n",
    "        raise   \n",
    "    pass\n",
    "for i in range(0, positions):\n",
    "    fig = plt.figure(figsize = (5,4))\n",
    "    fig.suptitle('Position %s'%(i + 1), fontsize = 20, fontweight = 'bold')\n",
    "    plt.plot(model_time_pt2[i], model_output_pt2[i], '--r', label = 'ideal pt2 model')\n",
    "    plt.plot(model_time_pt1[i], model_output_pt1[i], '--b', label = 'ideal pt1 model')\n",
    "    plt.legend()\n",
    "    for j in range(0, observations):\n",
    "        try:\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.plot(df_ist_soll[i][j] * m_factor_array[j]) \n",
    "        except:\n",
    "            pass\n",
    "    plt.savefig('Model_Validation/Position %s model.png'%(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
